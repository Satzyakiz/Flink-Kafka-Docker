WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.
02:27:01,706 INFO  org.myorg.quickstart.DataStreamJob                           [] - Kafka server: kafka-broker:29092
02:27:01,707 INFO  org.myorg.quickstart.DataStreamJob                           [] - Kafka source topic: data-from-file
02:27:01,708 INFO  org.myorg.quickstart.DataStreamJob                           [] - Kafka sink topic: processed-data
02:27:01,708 INFO  org.myorg.quickstart.DataStreamJob                           [] - Flink connecting to producer
02:27:01,713 WARN  org.apache.flink.connector.kafka.source.KafkaSourceBuilder   [] - Offset commit on checkpoint is disabled because group.id is not specified
02:27:01,728 INFO  org.myorg.quickstart.DataStreamJob                           [] - Flink connected to producer
02:27:01,728 INFO  org.myorg.quickstart.DataStreamJob                           [] - Flink connecting to consumer
02:27:01,757 INFO  org.myorg.quickstart.DataStreamJob                           [] - Flink connected to consumer
02:27:01,757 INFO  org.myorg.quickstart.DataStreamJob                           [] - Starting...
02:27:01,758 INFO  org.myorg.quickstart.DataStreamJob                           [] - Stopping...
02:27:01,880 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils [] - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
02:27:01,880 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils [] - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
02:27:01,881 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils [] - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
02:27:01,882 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils [] - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.
02:27:01,882 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils [] - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.
02:27:01,882 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils [] - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
02:27:01,884 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Starting Flink Mini Cluster
02:27:02,078 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Starting Metrics Registry
02:27:02,115 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
02:27:02,115 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Starting RPC Service(s)
02:27:02,124 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start local actor system
02:27:02,484 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
02:27:02,540 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka://flink
02:27:02,549 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start local actor system
02:27:02,561 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
02:27:02,570 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka://flink-metrics
02:27:02,580 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
02:27:02,602 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Created BLOB server storage directory /tmp/minicluster_c3baedeb07b8a7432edb28f360337fd8/blobStorage
02:27:02,609 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Started BLOB server at 0.0.0.0:33463 - max concurrent requests: 50 - max backlog: 1000
02:27:02,614 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Loading delegation token providers
02:27:02,617 INFO  org.apache.flink.runtime.security.token.hadoop.HadoopFSDelegationTokenProvider [] - Hadoop FS is not available (not packaged with this application): NoClassDefFoundError : "org/apache/hadoop/conf/Configuration".
02:27:02,617 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token provider hadoopfs loaded and initialized
02:27:02,618 INFO  org.apache.flink.runtime.security.token.hadoop.HBaseDelegationTokenProvider [] - HBase is not available (not packaged with this application): NoClassDefFoundError : "org/apache/hadoop/conf/Configuration".
02:27:02,622 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token provider hbase loaded and initialized
02:27:02,622 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token providers loaded successfully
02:27:02,623 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Loading delegation token receivers
02:27:02,624 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hadoopfs loaded and initialized
02:27:02,625 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hbase loaded and initialized
02:27:02,625 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receivers loaded successfully
02:27:02,625 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Checking provider and receiver instances consistency
02:27:02,625 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Provider and receiver instances are consistent
02:27:02,625 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Loading delegation token receivers
02:27:02,626 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hadoopfs loaded and initialized
02:27:02,626 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hbase loaded and initialized
02:27:02,626 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receivers loaded successfully
02:27:02,628 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Created BLOB cache storage directory /tmp/minicluster_c3baedeb07b8a7432edb28f360337fd8/blobStorage
02:27:02,630 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Created BLOB cache storage directory /tmp/minicluster_c3baedeb07b8a7432edb28f360337fd8/blobStorage
02:27:02,631 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Starting 1 TaskManager(s)
02:27:02,633 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Starting TaskManager with ResourceID: 3e373e43-6dc8-4896-924b-3e7eaa52bb79
02:27:02,647 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/tmp': total 1832 GB, usable 1686 GB (92.03% usable)
02:27:02,650 INFO  org.apache.flink.runtime.io.disk.iomanager.IOManager         [] - Created a new FileChannelManager for spilling of task related data to disk (joins, sorting, ...). Used directories:
	/tmp/flink-io-f71050e4-b421-4950-988d-48c6873eb971
02:27:02,655 INFO  org.apache.flink.runtime.io.network.NettyShuffleServiceFactory [] - Created a new FileChannelManager for storing result partitions of BLOCKING shuffles. Used directories:
	/tmp/flink-netty-shuffle-62bf98fb-4a24-4163-b991-f57e94800e58
02:27:02,686 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool [] - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
02:27:02,696 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Starting the network environment and its components.
02:27:02,697 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Starting the kvState service and its components.
02:27:02,708 INFO  org.apache.flink.configuration.Configuration                 [] - Config uses fallback configuration key 'akka.ask.timeout' instead of key 'taskmanager.slot.timeout'
02:27:02,716 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
02:27:02,728 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Start job leader service.
02:27:02,729 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /tmp/flink-dist-cache-ef6e129a-c2cb-4ef8-829f-c0fe7d6eb908
02:27:02,773 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Upload directory /tmp/flink-web-upload does not exist. 
02:27:02,774 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Created directory /tmp/flink-web-upload for file uploads.
02:27:02,775 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Starting rest endpoint.
02:27:02,776 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
02:27:02,900 WARN  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Log file environment variable 'log.file' is not set.
02:27:02,900 WARN  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
02:27:02,977 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Rest endpoint listening at localhost:45045
02:27:02,978 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Proposing leadership to contender http://localhost:45045
02:27:02,980 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - http://localhost:45045 was granted leadership with leaderSessionID=3c5b0d45-f29b-48f9-bbb0-78679c1be6a4
02:27:02,980 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Received confirmation of leadership for leader http://localhost:45045 , session=3c5b0d45-f29b-48f9-bbb0-78679c1be6a4
02:27:02,989 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner
02:27:02,989 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Starting resource manager service.
02:27:02,989 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Proposing leadership to contender LeaderContender: ResourceManagerServiceImpl
02:27:02,989 INFO  org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner [] - DefaultDispatcherRunner was granted leadership with leader id d18fce91-127b-42b5-9f38-d699e6dd1252. Creating new DispatcherLeaderProcess.
02:27:02,992 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Resource manager service is granted leadership with session id 040f483f-008f-4b1d-9505-5746ecacb12b.
02:27:02,993 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Flink Mini Cluster started successfully
02:27:02,995 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Start SessionDispatcherLeaderProcess.
02:27:03,000 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
02:27:03,000 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Recover all persisted job graphs that are not finished, yet.
02:27:03,000 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Successfully recovered 0 persisted job graphs.
02:27:03,010 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
02:27:03,012 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Starting the resource manager.
02:27:03,015 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Received confirmation of leadership for leader akka://flink/user/rpc/dispatcher_2 , session=d18fce91-127b-42b5-9f38-d699e6dd1252
02:27:03,018 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Starting tokens update task
02:27:03,019 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - No tokens obtained so skipping listener notification
02:27:03,019 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Tokens update task not started because either no tokens obtained or none of the tokens specified its renewal date
02:27:03,020 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Received confirmation of leadership for leader akka://flink/user/rpc/resourcemanager_1 , session=040f483f-008f-4b1d-9505-5746ecacb12b
02:27:03,021 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(95055746ecacb12b040f483f008f4b1d).
02:27:03,033 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Resolved ResourceManager address, beginning registration
02:27:03,038 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering TaskManager with ResourceID 3e373e43-6dc8-4896-924b-3e7eaa52bb79 (akka://flink/user/rpc/taskmanager_0) at ResourceManager
02:27:03,038 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'Kafka to Kafka Flink Job' (c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:03,039 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'Kafka to Kafka Flink Job' (c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:03,039 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 788fd7717cde301afa8a7ae8effef617.
02:27:03,047 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Proposing leadership to contender LeaderContender: JobMasterServiceLeadershipRunner
02:27:03,053 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
02:27:03,057 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'Kafka to Kafka Flink Job' (c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:03,069 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for Kafka to Kafka Flink Job (c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:03,083 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 55883b7bea480cdbd0ae999bb346dc7e for job c2e0e9306ea1dfc4e335ff8c4ab5a15d.
02:27:03,091 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job Kafka to Kafka Flink Job (c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:03,091 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
02:27:03,106 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 24 new pipelined regions in 1 ms, total 24 pipelined regions currently.
02:27:03,108 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@497460d7
02:27:03,108 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,109 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
02:27:03,120 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
02:27:03,123 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@500fb9d5 for Kafka to Kafka Flink Job (c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:03,127 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Received confirmation of leadership for leader akka://flink/user/rpc/jobmanager_3 , session=8e498539-36dc-49be-a39e-d67163a2534a
02:27:03,128 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'Kafka to Kafka Flink Job' (c2e0e9306ea1dfc4e335ff8c4ab5a15d) under job master id a39ed67163a2534a8e49853936dc49be.
02:27:03,130 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: Kafka Source.
02:27:03,131 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
02:27:03,131 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Kafka to Kafka Flink Job (c2e0e9306ea1dfc4e335ff8c4ab5a15d) switched from state CREATED to RUNNING.
02:27:03,134 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
02:27:03,137 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	bootstrap.servers = [kafka-broker:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = KafkaSource--3190457166694661885-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

02:27:03,144 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0) switched from CREATED to SCHEDULED.
02:27:03,145 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0) switched from CREATED to SCHEDULED.
02:27:03,146 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0) switched from CREATED to SCHEDULED.
02:27:03,147 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0) switched from CREATED to SCHEDULED.
02:27:03,147 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0) switched from CREATED to SCHEDULED.
02:27:03,147 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0) switched from CREATED to SCHEDULED.
02:27:03,148 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0) switched from CREATED to SCHEDULED.
02:27:03,148 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0) switched from CREATED to SCHEDULED.
02:27:03,149 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0) switched from CREATED to SCHEDULED.
02:27:03,149 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0) switched from CREATED to SCHEDULED.
02:27:03,149 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0) switched from CREATED to SCHEDULED.
02:27:03,150 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0) switched from CREATED to SCHEDULED.
02:27:03,150 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0) switched from CREATED to SCHEDULED.
02:27:03,150 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0) switched from CREATED to SCHEDULED.
02:27:03,151 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0) switched from CREATED to SCHEDULED.
02:27:03,151 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0) switched from CREATED to SCHEDULED.
02:27:03,152 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0) switched from CREATED to SCHEDULED.
02:27:03,152 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0) switched from CREATED to SCHEDULED.
02:27:03,152 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0) switched from CREATED to SCHEDULED.
02:27:03,153 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0) switched from CREATED to SCHEDULED.
02:27:03,153 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0) switched from CREATED to SCHEDULED.
02:27:03,153 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0) switched from CREATED to SCHEDULED.
02:27:03,154 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0) switched from CREATED to SCHEDULED.
02:27:03,154 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(95055746ecacb12b040f483f008f4b1d)
02:27:03,156 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
02:27:03,157 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager a39ed67163a2534a8e49853936dc49be@akka://flink/user/rpc/jobmanager_3 for job c2e0e9306ea1dfc4e335ff8c4ab5a15d.
02:27:03,159 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager a39ed67163a2534a8e49853936dc49be@akka://flink/user/rpc/jobmanager_3 for job c2e0e9306ea1dfc4e335ff8c4ab5a15d.
02:27:03,160 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 95055746ecacb12b040f483f008f4b1d.
02:27:03,161 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=24}]
02:27:03,169 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
02:27:03,169 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'commit.offsets.on.checkpoint' was supplied but isn't a known config.
02:27:03,169 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
02:27:03,169 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'enable.auto.commit' was supplied but isn't a known config.
02:27:03,170 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'client.id.prefix' was supplied but isn't a known config.
02:27:03,170 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
02:27:03,170 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'auto.offset.reset' was supplied but isn't a known config.
02:27:03,170 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,170 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,170 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223170
02:27:03,171 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group null without periodic partition discovery.
02:27:03,176 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3190457166694661885-enumerator-admin-client] Node -1 disconnected.
02:27:03,177 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3190457166694661885-enumerator-admin-client] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,234 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 69dc6000936efeda0ba34db308f835ce for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,236 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 69dc6000936efeda0ba34db308f835ce.
02:27:03,237 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job c2e0e9306ea1dfc4e335ff8c4ab5a15d for job leader monitoring.
02:27:03,238 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 8e498539-36dc-49be-a39e-d67163a2534a.
02:27:03,238 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 2aa578c9f93d8abb167860f49ca0cd5f for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,238 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 2aa578c9f93d8abb167860f49ca0cd5f.
02:27:03,238 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 60b321522a0bc2f7a4a97b4e4266645e for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,238 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 60b321522a0bc2f7a4a97b4e4266645e.
02:27:03,238 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request a92bf3cb67ef7b3cd0734a35990510dc for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for a92bf3cb67ef7b3cd0734a35990510dc.
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 77b73d7ad0d9f8571a72b8f2635d873d for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 77b73d7ad0d9f8571a72b8f2635d873d.
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 3237b3bf43689ae7c5cb57391c36260a for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 3237b3bf43689ae7c5cb57391c36260a.
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 4a0df5520309015316fb0619fde06b06 for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 4a0df5520309015316fb0619fde06b06.
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 6b2b5bcf48e8d4fdc0410f1c5618257e for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 6b2b5bcf48e8d4fdc0410f1c5618257e.
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request f6c1e17451f8b6b70c3d09a59df2f9e5 for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for f6c1e17451f8b6b70c3d09a59df2f9e5.
02:27:03,239 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 08e61f27f2ccfe7592cc32a15c0c0a9f for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,240 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 08e61f27f2ccfe7592cc32a15c0c0a9f.
02:27:03,240 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 7a44a6be6f9e4244ab721a5aed80da1d for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,240 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 7a44a6be6f9e4244ab721a5aed80da1d.
02:27:03,240 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 695c3d7aa456d87bbe03ccadde11ba29 for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,240 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 695c3d7aa456d87bbe03ccadde11ba29.
02:27:03,240 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 5dc2bad53db9c92fc41ad760fa095c82 for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,240 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 5dc2bad53db9c92fc41ad760fa095c82.
02:27:03,240 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 94128f7d6482e2eb2647d2cd12b458ab for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,240 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 94128f7d6482e2eb2647d2cd12b458ab.
02:27:03,240 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 3e7b389f3d26e6a0e55250c2f16abaff for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,240 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 3e7b389f3d26e6a0e55250c2f16abaff.
02:27:03,241 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request d4cf2367add5feda1c4e55aceabaf109 for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,241 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for d4cf2367add5feda1c4e55aceabaf109.
02:27:03,241 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 038dc4c817d1f6342a2dbff33c66a712 for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,241 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 038dc4c817d1f6342a2dbff33c66a712.
02:27:03,241 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 7c10e978ec4ce10eaaf6419f02d76afa for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,241 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 7c10e978ec4ce10eaaf6419f02d76afa.
02:27:03,241 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 34f0823f071c2e7c302ad04356ba284b for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,241 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 34f0823f071c2e7c302ad04356ba284b.
02:27:03,241 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 712070707dd75481d781af1996cdd18a for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,241 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 712070707dd75481d781af1996cdd18a.
02:27:03,241 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request ca8016b587b88b7c54ee776c25e2cad1 for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,242 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for ca8016b587b88b7c54ee776c25e2cad1.
02:27:03,242 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 29cbb2136d094ce24399c336eecde99a for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,242 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 29cbb2136d094ce24399c336eecde99a.
02:27:03,242 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request f65bbf25234b892dfed65e0ad8eb1ddc for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,242 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for f65bbf25234b892dfed65e0ad8eb1ddc.
02:27:03,242 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 4c1eefaaa8ebc9136abe20355cf9185b for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from resource manager with leader id 95055746ecacb12b040f483f008f4b1d.
02:27:03,242 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 4c1eefaaa8ebc9136abe20355cf9185b.
02:27:03,243 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job c2e0e9306ea1dfc4e335ff8c4ab5a15d.
02:27:03,244 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job c2e0e9306ea1dfc4e335ff8c4ab5a15d.
02:27:03,245 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job c2e0e9306ea1dfc4e335ff8c4ab5a15d.
02:27:03,247 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
02:27:03,248 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id ca8016b587b88b7c54ee776c25e2cad1
02:27:03,250 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0) switched from SCHEDULED to DEPLOYING.
02:27:03,250 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_1 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 4a0df5520309015316fb0619fde06b06
02:27:03,250 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot ca8016b587b88b7c54ee776c25e2cad1.
02:27:03,250 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0) switched from SCHEDULED to DEPLOYING.
02:27:03,250 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_2 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 60b321522a0bc2f7a4a97b4e4266645e
02:27:03,250 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0) switched from SCHEDULED to DEPLOYING.
02:27:03,251 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_3 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 77b73d7ad0d9f8571a72b8f2635d873d
02:27:03,251 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0) switched from SCHEDULED to DEPLOYING.
02:27:03,251 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_4 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 4c1eefaaa8ebc9136abe20355cf9185b
02:27:03,251 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0) switched from SCHEDULED to DEPLOYING.
02:27:03,251 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_5 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 08e61f27f2ccfe7592cc32a15c0c0a9f
02:27:03,251 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0) switched from SCHEDULED to DEPLOYING.
02:27:03,251 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_6 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 3e7b389f3d26e6a0e55250c2f16abaff
02:27:03,251 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0) switched from SCHEDULED to DEPLOYING.
02:27:03,251 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_7 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 3237b3bf43689ae7c5cb57391c36260a
02:27:03,252 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0) switched from SCHEDULED to DEPLOYING.
02:27:03,252 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_8 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 6b2b5bcf48e8d4fdc0410f1c5618257e
02:27:03,252 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0) switched from SCHEDULED to DEPLOYING.
02:27:03,252 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_9 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 038dc4c817d1f6342a2dbff33c66a712
02:27:03,252 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0) switched from SCHEDULED to DEPLOYING.
02:27:03,252 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_10 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 29cbb2136d094ce24399c336eecde99a
02:27:03,252 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0) switched from SCHEDULED to DEPLOYING.
02:27:03,252 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_11 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id a92bf3cb67ef7b3cd0734a35990510dc
02:27:03,252 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0) switched from SCHEDULED to DEPLOYING.
02:27:03,252 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_12 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 69dc6000936efeda0ba34db308f835ce
02:27:03,253 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0) switched from SCHEDULED to DEPLOYING.
02:27:03,253 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_13 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 7c10e978ec4ce10eaaf6419f02d76afa
02:27:03,253 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0) switched from SCHEDULED to DEPLOYING.
02:27:03,253 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_14 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 5dc2bad53db9c92fc41ad760fa095c82
02:27:03,253 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0) switched from SCHEDULED to DEPLOYING.
02:27:03,253 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_15 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 94128f7d6482e2eb2647d2cd12b458ab
02:27:03,253 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0) switched from SCHEDULED to DEPLOYING.
02:27:03,253 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_16 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id f65bbf25234b892dfed65e0ad8eb1ddc
02:27:03,254 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0) switched from SCHEDULED to DEPLOYING.
02:27:03,254 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_17 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id f6c1e17451f8b6b70c3d09a59df2f9e5
02:27:03,254 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0) switched from SCHEDULED to DEPLOYING.
02:27:03,254 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_18 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 7a44a6be6f9e4244ab721a5aed80da1d
02:27:03,254 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0) switched from SCHEDULED to DEPLOYING.
02:27:03,254 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_19 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id d4cf2367add5feda1c4e55aceabaf109
02:27:03,254 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0) switched from SCHEDULED to DEPLOYING.
02:27:03,254 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_20 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 34f0823f071c2e7c302ad04356ba284b
02:27:03,254 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0) switched from SCHEDULED to DEPLOYING.
02:27:03,254 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_21 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 2aa578c9f93d8abb167860f49ca0cd5f
02:27:03,255 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0) switched from SCHEDULED to DEPLOYING.
02:27:03,255 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_22 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 712070707dd75481d781af1996cdd18a
02:27:03,255 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0) switched from SCHEDULED to DEPLOYING.
02:27:03,255 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24) (attempt #0) with attempt id 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_23 to 3e373e43-6dc8-4896-924b-3e7eaa52bb79 @ localhost (dataPort=-1) with allocation id 695c3d7aa456d87bbe03ccadde11ba29
02:27:03,256 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - StateChangelogStorageLoader initialized with shortcut names {memory}.
02:27:03,256 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
02:27:03,259 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id c2e0e9306ea1dfc4e335ff8c4ab5a15d
02:27:03,263 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id ca8016b587b88b7c54ee776c25e2cad1.
02:27:03,263 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
02:27:03,266 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
02:27:03,266 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 4a0df5520309015316fb0619fde06b06.
02:27:03,267 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0), deploy into slot with allocation id 4a0df5520309015316fb0619fde06b06.
02:27:03,268 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 60b321522a0bc2f7a4a97b4e4266645e.
02:27:03,267 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0) switched from CREATED to DEPLOYING.
02:27:03,268 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0) [DEPLOYING].
02:27:03,269 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0), deploy into slot with allocation id 60b321522a0bc2f7a4a97b4e4266645e.
02:27:03,269 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 77b73d7ad0d9f8571a72b8f2635d873d.
02:27:03,269 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0) switched from CREATED to DEPLOYING.
02:27:03,270 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0) [DEPLOYING].
02:27:03,271 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0), deploy into slot with allocation id 77b73d7ad0d9f8571a72b8f2635d873d.
02:27:03,271 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 4c1eefaaa8ebc9136abe20355cf9185b.
02:27:03,271 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0) switched from CREATED to DEPLOYING.
02:27:03,271 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0) [DEPLOYING].
02:27:03,272 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0), deploy into slot with allocation id 4c1eefaaa8ebc9136abe20355cf9185b.
02:27:03,273 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 08e61f27f2ccfe7592cc32a15c0c0a9f.
02:27:03,272 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0) switched from CREATED to DEPLOYING.
02:27:03,273 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0) [DEPLOYING].
02:27:03,274 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0), deploy into slot with allocation id 08e61f27f2ccfe7592cc32a15c0c0a9f.
02:27:03,274 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 3e7b389f3d26e6a0e55250c2f16abaff.
02:27:03,274 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0) switched from CREATED to DEPLOYING.
02:27:03,274 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0) [DEPLOYING].
02:27:03,275 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0), deploy into slot with allocation id 3e7b389f3d26e6a0e55250c2f16abaff.
02:27:03,275 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0) switched from CREATED to DEPLOYING.
02:27:03,275 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 3237b3bf43689ae7c5cb57391c36260a.
02:27:03,275 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0) [DEPLOYING].
02:27:03,276 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0), deploy into slot with allocation id 3237b3bf43689ae7c5cb57391c36260a.
02:27:03,277 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 6b2b5bcf48e8d4fdc0410f1c5618257e.
02:27:03,277 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0) switched from CREATED to DEPLOYING.
02:27:03,277 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0) [DEPLOYING].
02:27:03,277 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6e5a511
02:27:03,277 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@64aa090a
02:27:03,277 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1c5b0d7e
02:27:03,277 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,277 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,277 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,277 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,277 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,277 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,278 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0), deploy into slot with allocation id 6b2b5bcf48e8d4fdc0410f1c5618257e.
02:27:03,278 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3647e543
02:27:03,277 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6a6d704b
02:27:03,278 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,278 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@67c732bc
02:27:03,278 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,278 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,278 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,278 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,278 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,278 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 038dc4c817d1f6342a2dbff33c66a712.
02:27:03,278 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0) switched from CREATED to DEPLOYING.
02:27:03,278 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5606e265
02:27:03,278 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3190457166694661885-enumerator-admin-client] Node -1 disconnected.
02:27:03,278 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,278 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0) [DEPLOYING].
02:27:03,278 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3190457166694661885-enumerator-admin-client] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,278 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,278 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@50387652
02:27:03,278 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,278 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,279 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0), deploy into slot with allocation id 038dc4c817d1f6342a2dbff33c66a712.
02:27:03,279 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@4e2eeba
02:27:03,279 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,279 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0) switched from CREATED to DEPLOYING.
02:27:03,279 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 29cbb2136d094ce24399c336eecde99a.
02:27:03,279 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,279 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0) [DEPLOYING].
02:27:03,279 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@21d6bd3a
02:27:03,279 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,279 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,280 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0), deploy into slot with allocation id 29cbb2136d094ce24399c336eecde99a.
02:27:03,280 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0) switched from CREATED to DEPLOYING.
02:27:03,280 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot a92bf3cb67ef7b3cd0734a35990510dc.
02:27:03,280 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0) [DEPLOYING].
02:27:03,281 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3df49ed6
02:27:03,281 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,281 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,281 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0) switched from DEPLOYING to INITIALIZING.
02:27:03,281 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0) switched from DEPLOYING to INITIALIZING.
02:27:03,281 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0) switched from DEPLOYING to INITIALIZING.
02:27:03,281 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0) switched from DEPLOYING to INITIALIZING.
02:27:03,281 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0) switched from DEPLOYING to INITIALIZING.
02:27:03,281 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0) switched from DEPLOYING to INITIALIZING.
02:27:03,281 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0) switched from DEPLOYING to INITIALIZING.
02:27:03,281 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0), deploy into slot with allocation id a92bf3cb67ef7b3cd0734a35990510dc.
02:27:03,281 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
02:27:03,281 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0) switched from DEPLOYING to INITIALIZING.
02:27:03,281 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0) switched from DEPLOYING to INITIALIZING.
02:27:03,281 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0) switched from DEPLOYING to INITIALIZING.
02:27:03,282 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0) switched from CREATED to DEPLOYING.
02:27:03,282 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 69dc6000936efeda0ba34db308f835ce.
02:27:03,282 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0) switched from DEPLOYING to INITIALIZING.
02:27:03,282 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0) [DEPLOYING].
02:27:03,283 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0), deploy into slot with allocation id 69dc6000936efeda0ba34db308f835ce.
02:27:03,283 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@540b347f
02:27:03,283 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,283 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,283 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 7c10e978ec4ce10eaaf6419f02d76afa.
02:27:03,283 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0) switched from CREATED to DEPLOYING.
02:27:03,283 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0) [DEPLOYING].
02:27:03,284 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0) switched from DEPLOYING to INITIALIZING.
02:27:03,284 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@5cf86fed
02:27:03,284 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,284 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,284 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0) switched from DEPLOYING to INITIALIZING.
02:27:03,284 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0) switched from DEPLOYING to INITIALIZING.
02:27:03,285 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0) switched from DEPLOYING to INITIALIZING.
02:27:03,285 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0) switched from DEPLOYING to INITIALIZING.
02:27:03,285 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0) switched from DEPLOYING to INITIALIZING.
02:27:03,285 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0), deploy into slot with allocation id 7c10e978ec4ce10eaaf6419f02d76afa.
02:27:03,286 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0) switched from DEPLOYING to INITIALIZING.
02:27:03,286 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0) switched from CREATED to DEPLOYING.
02:27:03,286 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 5dc2bad53db9c92fc41ad760fa095c82.
02:27:03,286 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0) [DEPLOYING].
02:27:03,286 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@370bfb92
02:27:03,287 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,287 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,291 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0), deploy into slot with allocation id 5dc2bad53db9c92fc41ad760fa095c82.
02:27:03,291 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0) switched from DEPLOYING to INITIALIZING.
02:27:03,293 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
02:27:03,293 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0) switched from CREATED to DEPLOYING.
02:27:03,293 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 94128f7d6482e2eb2647d2cd12b458ab.
02:27:03,294 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0) switched from DEPLOYING to INITIALIZING.
02:27:03,294 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0) [DEPLOYING].
02:27:03,294 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0) switched from DEPLOYING to INITIALIZING.
02:27:03,294 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0) switched from DEPLOYING to INITIALIZING.
02:27:03,294 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0) switched from DEPLOYING to INITIALIZING.
02:27:03,294 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0), deploy into slot with allocation id 94128f7d6482e2eb2647d2cd12b458ab.
02:27:03,294 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0) switched from DEPLOYING to INITIALIZING.
02:27:03,294 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@6d31ba72
02:27:03,294 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0) switched from DEPLOYING to INITIALIZING.
02:27:03,294 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,294 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f65bbf25234b892dfed65e0ad8eb1ddc.
02:27:03,294 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,295 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0) switched from DEPLOYING to INITIALIZING.
02:27:03,295 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0) switched from DEPLOYING to INITIALIZING.
02:27:03,295 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0) switched from DEPLOYING to INITIALIZING.
02:27:03,295 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0), deploy into slot with allocation id f65bbf25234b892dfed65e0ad8eb1ddc.
02:27:03,295 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f6c1e17451f8b6b70c3d09a59df2f9e5.
02:27:03,295 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0) switched from CREATED to DEPLOYING.
02:27:03,295 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0) [DEPLOYING].
02:27:03,296 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3304888b
02:27:03,296 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,296 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,296 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0) switched from DEPLOYING to INITIALIZING.
02:27:03,296 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0) switched from CREATED to DEPLOYING.
02:27:03,296 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0), deploy into slot with allocation id f6c1e17451f8b6b70c3d09a59df2f9e5.
02:27:03,296 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0) [DEPLOYING].
02:27:03,296 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0) switched from CREATED to DEPLOYING.
02:27:03,296 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 7a44a6be6f9e4244ab721a5aed80da1d.
02:27:03,296 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0) [DEPLOYING].
02:27:03,296 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@505457fb
02:27:03,296 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,296 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,296 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0) switched from DEPLOYING to INITIALIZING.
02:27:03,297 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2b782c1
02:27:03,297 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,297 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,297 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0), deploy into slot with allocation id 7a44a6be6f9e4244ab721a5aed80da1d.
02:27:03,297 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0) switched from DEPLOYING to INITIALIZING.
02:27:03,297 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0) switched from CREATED to DEPLOYING.
02:27:03,297 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot d4cf2367add5feda1c4e55aceabaf109.
02:27:03,297 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0) [DEPLOYING].
02:27:03,297 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@735f5b8f
02:27:03,297 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,297 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,298 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0) switched from DEPLOYING to INITIALIZING.
02:27:03,298 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0) switched from DEPLOYING to INITIALIZING.
02:27:03,298 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0) switched from DEPLOYING to INITIALIZING.
02:27:03,298 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0), deploy into slot with allocation id d4cf2367add5feda1c4e55aceabaf109.
02:27:03,298 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0) switched from DEPLOYING to INITIALIZING.
02:27:03,298 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 34f0823f071c2e7c302ad04356ba284b.
02:27:03,298 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0) switched from CREATED to DEPLOYING.
02:27:03,299 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0) switched from DEPLOYING to INITIALIZING.
02:27:03,299 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0) [DEPLOYING].
02:27:03,299 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0), deploy into slot with allocation id 34f0823f071c2e7c302ad04356ba284b.
02:27:03,299 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@66b27287
02:27:03,299 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,299 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,299 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0) switched from DEPLOYING to INITIALIZING.
02:27:03,299 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0) switched from DEPLOYING to INITIALIZING.
02:27:03,304 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 2aa578c9f93d8abb167860f49ca0cd5f.
02:27:03,304 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0) switched from CREATED to DEPLOYING.
02:27:03,304 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0) [DEPLOYING].
02:27:03,304 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@103de90b
02:27:03,304 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,304 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,304 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0) switched from DEPLOYING to INITIALIZING.
02:27:03,304 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0), deploy into slot with allocation id 2aa578c9f93d8abb167860f49ca0cd5f.
02:27:03,305 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0) switched from DEPLOYING to INITIALIZING.
02:27:03,305 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 712070707dd75481d781af1996cdd18a.
02:27:03,305 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0) switched from CREATED to DEPLOYING.
02:27:03,305 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0) [DEPLOYING].
02:27:03,305 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0), deploy into slot with allocation id 712070707dd75481d781af1996cdd18a.
02:27:03,306 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0) switched from CREATED to DEPLOYING.
02:27:03,306 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0) [DEPLOYING].
02:27:03,306 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 695c3d7aa456d87bbe03ccadde11ba29.
02:27:03,306 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@1ce96f2a
02:27:03,306 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@19b177d
02:27:03,306 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,306 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,306 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,306 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,306 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0) switched from DEPLOYING to INITIALIZING.
02:27:03,306 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0) switched from DEPLOYING to INITIALIZING.
02:27:03,306 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0) switched from DEPLOYING to INITIALIZING.
02:27:03,307 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0) switched from DEPLOYING to INITIALIZING.
02:27:03,308 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0), deploy into slot with allocation id 695c3d7aa456d87bbe03ccadde11ba29.
02:27:03,308 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0) switched from CREATED to DEPLOYING.
02:27:03,309 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0) [DEPLOYING].
02:27:03,309 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot ca8016b587b88b7c54ee776c25e2cad1.
02:27:03,309 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@14432db5
02:27:03,309 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
02:27:03,309 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
02:27:03,309 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0) switched from DEPLOYING to INITIALIZING.
02:27:03,309 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 4a0df5520309015316fb0619fde06b06.
02:27:03,309 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 60b321522a0bc2f7a4a97b4e4266645e.
02:27:03,309 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0) switched from DEPLOYING to INITIALIZING.
02:27:03,309 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 77b73d7ad0d9f8571a72b8f2635d873d.
02:27:03,309 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 4c1eefaaa8ebc9136abe20355cf9185b.
02:27:03,309 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 08e61f27f2ccfe7592cc32a15c0c0a9f.
02:27:03,309 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 3e7b389f3d26e6a0e55250c2f16abaff.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 3237b3bf43689ae7c5cb57391c36260a.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 6b2b5bcf48e8d4fdc0410f1c5618257e.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 038dc4c817d1f6342a2dbff33c66a712.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 29cbb2136d094ce24399c336eecde99a.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot a92bf3cb67ef7b3cd0734a35990510dc.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 69dc6000936efeda0ba34db308f835ce.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 7c10e978ec4ce10eaaf6419f02d76afa.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 5dc2bad53db9c92fc41ad760fa095c82.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 94128f7d6482e2eb2647d2cd12b458ab.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f65bbf25234b892dfed65e0ad8eb1ddc.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot f6c1e17451f8b6b70c3d09a59df2f9e5.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 7a44a6be6f9e4244ab721a5aed80da1d.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot d4cf2367add5feda1c4e55aceabaf109.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 34f0823f071c2e7c302ad04356ba284b.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 2aa578c9f93d8abb167860f49ca0cd5f.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 712070707dd75481d781af1996cdd18a.
02:27:03,310 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 695c3d7aa456d87bbe03ccadde11ba29.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,318 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,318 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,318 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,318 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,317 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,318 WARN  org.apache.flink.connector.kafka.source.reader.KafkaSourceReader [] - Offset commit on checkpoint is disabled. Consuming offset will not be reported back to Kafka cluster.
02:27:03,348 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-6
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,347 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-5
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,347 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,348 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-10
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,348 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-9
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,348 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-8
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,347 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-4
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,348 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-7
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,348 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-13
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,349 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-14
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,347 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,347 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,349 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-15
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,348 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-12
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,348 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-11
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,349 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-16
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,354 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-17
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,354 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-19
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,354 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-18
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,354 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-20
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,354 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-21
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,354 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-23
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,354 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-22
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,354 INFO  org.apache.kafka.clients.producer.ProducerConfig             [] - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [kafka-broker:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-24
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-13] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-1] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-3] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-22] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-20] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-9] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-4] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-21] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-2] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-10] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-6] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-12] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-11] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-8] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-5] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-16] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-19] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-24] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-17] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-23] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-15] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-14] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-18] Instantiated an idempotent producer.
02:27:03,360 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-7] Instantiated an idempotent producer.
02:27:03,394 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,394 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,394 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223394
02:27:03,397 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,397 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,397 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223397
02:27:03,399 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,399 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,399 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223399
02:27:03,399 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,399 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,399 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223397
02:27:03,400 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,400 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,400 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223397
02:27:03,400 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,400 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,400 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223397
02:27:03,400 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,400 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,400 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223396
02:27:03,400 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,400 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,400 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223396
02:27:03,401 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,401 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,401 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223396
02:27:03,401 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,401 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,401 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223395
02:27:03,401 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,401 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,401 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223395
02:27:03,401 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,401 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,401 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223400
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223400
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223399
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223399
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223399
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,402 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223399
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223398
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223398
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223398
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223397
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,403 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223397
02:27:03,414 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,415 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,415 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223414
02:27:03,415 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
02:27:03,415 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
02:27:03,415 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1698287223414
02:27:03,419 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 14 (#0) @ 
02:27:03,419 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 16 (#0) @ 
02:27:03,419 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 19 (#0) @ 
02:27:03,419 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 3 (#0) @ 
02:27:03,419 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 12 (#0) @ 
02:27:03,420 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 18 (#0) @ 
02:27:03,420 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 11 (#0) @ 
02:27:03,422 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 17 (#0) @ 
02:27:03,422 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 23 (#0) @ 
02:27:03,422 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 8 (#0) @ 
02:27:03,423 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 6 (#0) @ 
02:27:03,423 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 4 (#0) @ 
02:27:03,423 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 20 (#0) @ 
02:27:03,424 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 10 (#0) @ 
02:27:03,424 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 15 (#0) @ 
02:27:03,424 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 9 (#0) @ 
02:27:03,425 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0) switched from INITIALIZING to RUNNING.
02:27:03,425 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 0 (#0) @ 
02:27:03,425 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 22 (#0) @ 
02:27:03,425 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0) switched from INITIALIZING to RUNNING.
02:27:03,425 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 5 (#0) @ 
02:27:03,425 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 13 (#0) @ 
02:27:03,425 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0) switched from INITIALIZING to RUNNING.
02:27:03,425 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0) switched from INITIALIZING to RUNNING.
02:27:03,426 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0) switched from INITIALIZING to RUNNING.
02:27:03,427 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0) switched from INITIALIZING to RUNNING.
02:27:03,427 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 2 (#0) @ 
02:27:03,427 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 7 (#0) @ 
02:27:03,427 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0) switched from INITIALIZING to RUNNING.
02:27:03,427 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0) switched from INITIALIZING to RUNNING.
02:27:03,427 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0) switched from INITIALIZING to RUNNING.
02:27:03,428 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0) switched from INITIALIZING to RUNNING.
02:27:03,428 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0) switched from INITIALIZING to RUNNING.
02:27:03,428 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0) switched from INITIALIZING to RUNNING.
02:27:03,428 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0) switched from INITIALIZING to RUNNING.
02:27:03,428 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0) switched from INITIALIZING to RUNNING.
02:27:03,428 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0) switched from INITIALIZING to RUNNING.
02:27:03,428 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0) switched from INITIALIZING to RUNNING.
02:27:03,429 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0) switched from INITIALIZING to RUNNING.
02:27:03,429 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0) switched from INITIALIZING to RUNNING.
02:27:03,429 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0) switched from INITIALIZING to RUNNING.
02:27:03,429 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0) switched from INITIALIZING to RUNNING.
02:27:03,429 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0) switched from INITIALIZING to RUNNING.
02:27:03,430 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0) switched from INITIALIZING to RUNNING.
02:27:03,430 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0) switched from INITIALIZING to RUNNING.
02:27:03,430 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0) switched from INITIALIZING to RUNNING.
02:27:03,430 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0) switched from INITIALIZING to RUNNING.
02:27:03,430 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0) switched from INITIALIZING to RUNNING.
02:27:03,430 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0) switched from INITIALIZING to RUNNING.
02:27:03,431 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0) switched from INITIALIZING to RUNNING.
02:27:03,431 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 21 (#0) @ 
02:27:03,438 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0) switched from INITIALIZING to RUNNING.
02:27:03,438 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0) switched from INITIALIZING to RUNNING.
02:27:03,438 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0) switched from INITIALIZING to RUNNING.
02:27:03,438 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0) switched from INITIALIZING to RUNNING.
02:27:03,438 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0) switched from INITIALIZING to RUNNING.
02:27:03,438 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0) switched from INITIALIZING to RUNNING.
02:27:03,438 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0) switched from INITIALIZING to RUNNING.
02:27:03,439 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0) switched from INITIALIZING to RUNNING.
02:27:03,442 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0) switched from INITIALIZING to RUNNING.
02:27:03,442 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0) switched from INITIALIZING to RUNNING.
02:27:03,442 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0) switched from INITIALIZING to RUNNING.
02:27:03,442 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
02:27:03,442 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 1 (#0) @ 
02:27:03,442 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0) switched from INITIALIZING to RUNNING.
02:27:03,442 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0) switched from INITIALIZING to RUNNING.
02:27:03,443 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0) switched from INITIALIZING to RUNNING.
02:27:03,443 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0) switched from INITIALIZING to RUNNING.
02:27:03,443 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0) switched from INITIALIZING to RUNNING.
02:27:03,443 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
02:27:03,443 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0) switched from INITIALIZING to RUNNING.
02:27:03,444 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0) switched from INITIALIZING to RUNNING.
02:27:03,479 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3190457166694661885-enumerator-admin-client] Node -1 disconnected.
02:27:03,480 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3190457166694661885-enumerator-admin-client] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,487 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Node -1 disconnected.
02:27:03,487 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,487 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,487 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Node -1 disconnected.
02:27:03,488 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,488 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,488 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Node -1 disconnected.
02:27:03,488 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Node -1 disconnected.
02:27:03,488 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Node -1 disconnected.
02:27:03,488 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,488 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,489 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Node -1 disconnected.
02:27:03,489 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Node -1 disconnected.
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,489 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Node -1 disconnected.
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,489 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Node -1 disconnected.
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,489 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Node -1 disconnected.
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,489 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,490 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Node -1 disconnected.
02:27:03,490 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,490 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Node -1 disconnected.
02:27:03,490 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,490 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,490 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,490 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Node -1 disconnected.
02:27:03,490 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,490 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,490 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node -1 disconnected.
02:27:03,490 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,490 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,491 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Node -1 disconnected.
02:27:03,491 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,491 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,491 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Node -1 disconnected.
02:27:03,491 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,491 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,491 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Node -1 disconnected.
02:27:03,491 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Node -1 disconnected.
02:27:03,491 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,491 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,491 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,491 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Node -1 disconnected.
02:27:03,491 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,491 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,491 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,491 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Node -1 disconnected.
02:27:03,491 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,491 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,491 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Node -1 disconnected.
02:27:03,492 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,491 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Node -1 disconnected.
02:27:03,492 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,492 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,492 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,494 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Node -1 disconnected.
02:27:03,494 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Node -1 disconnected.
02:27:03,494 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,494 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,495 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,495 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,589 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Node -1 disconnected.
02:27:03,589 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,589 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,589 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Node -1 disconnected.
02:27:03,589 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Node -1 disconnected.
02:27:03,589 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,589 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,589 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,589 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,589 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Node -1 disconnected.
02:27:03,589 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Node -1 disconnected.
02:27:03,589 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,589 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,589 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,589 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,589 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Node -1 disconnected.
02:27:03,590 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,590 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,590 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Node -1 disconnected.
02:27:03,590 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,590 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,590 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Node -1 disconnected.
02:27:03,590 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Node -1 disconnected.
02:27:03,590 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,590 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,590 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Node -1 disconnected.
02:27:03,590 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,590 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,590 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,590 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,590 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Node -1 disconnected.
02:27:03,591 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,591 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Node -1 disconnected.
02:27:03,591 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,591 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,591 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,591 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node -1 disconnected.
02:27:03,591 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,591 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,591 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Node -1 disconnected.
02:27:03,591 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,591 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,591 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Node -1 disconnected.
02:27:03,591 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,591 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,591 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Node -1 disconnected.
02:27:03,591 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Node -1 disconnected.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,592 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Node -1 disconnected.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,592 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Node -1 disconnected.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,592 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Node -1 disconnected.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,592 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Node -1 disconnected.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,592 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Node -1 disconnected.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,592 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,595 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Node -1 disconnected.
02:27:03,595 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,595 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,595 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Node -1 disconnected.
02:27:03,595 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,595 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,681 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3190457166694661885-enumerator-admin-client] Node -1 disconnected.
02:27:03,681 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3190457166694661885-enumerator-admin-client] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,689 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Node -1 disconnected.
02:27:03,690 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,690 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,690 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Node -1 disconnected.
02:27:03,690 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,690 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,690 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Node -1 disconnected.
02:27:03,690 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,690 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,691 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Node -1 disconnected.
02:27:03,691 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Node -1 disconnected.
02:27:03,691 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,691 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,691 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,691 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,691 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Node -1 disconnected.
02:27:03,691 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,691 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,692 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Node -1 disconnected.
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,692 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Node -1 disconnected.
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,692 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Node -1 disconnected.
02:27:03,692 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Node -1 disconnected.
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,692 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Node -1 disconnected.
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,692 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Node -1 disconnected.
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,692 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Node -1 disconnected.
02:27:03,692 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,693 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,696 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Node -1 disconnected.
02:27:03,696 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,696 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,740 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Node -1 disconnected.
02:27:03,740 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,740 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,740 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Node -1 disconnected.
02:27:03,740 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,740 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,741 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Node -1 disconnected.
02:27:03,741 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,741 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Node -1 disconnected.
02:27:03,741 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,741 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Node -1 disconnected.
02:27:03,741 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node -1 disconnected.
02:27:03,741 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,741 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,741 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,741 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,741 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,741 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,741 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Node -1 disconnected.
02:27:03,741 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,742 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,743 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Node -1 disconnected.
02:27:03,743 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,743 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,743 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Node -1 disconnected.
02:27:03,743 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,743 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,746 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Node -1 disconnected.
02:27:03,746 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,746 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,891 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Node -1 disconnected.
02:27:03,891 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,891 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,892 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Node -1 disconnected.
02:27:03,892 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Node -1 disconnected.
02:27:03,892 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,892 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,892 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,892 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,893 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Node -1 disconnected.
02:27:03,893 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Node -1 disconnected.
02:27:03,893 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Node -1 disconnected.
02:27:03,893 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,893 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,893 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,893 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,893 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,893 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,893 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Node -1 disconnected.
02:27:03,893 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,893 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,898 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Node -1 disconnected.
02:27:03,898 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,898 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,941 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Node -1 disconnected.
02:27:03,941 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Node -1 disconnected.
02:27:03,941 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Node -1 disconnected.
02:27:03,941 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,941 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,941 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,941 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,941 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,941 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,942 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Node -1 disconnected.
02:27:03,942 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,942 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,942 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Node -1 disconnected.
02:27:03,942 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,942 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,942 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Node -1 disconnected.
02:27:03,942 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Node -1 disconnected.
02:27:03,942 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,942 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,942 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,942 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,942 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Node -1 disconnected.
02:27:03,942 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,942 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,943 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Node -1 disconnected.
02:27:03,943 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,943 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,943 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Node -1 disconnected.
02:27:03,943 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,943 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,943 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Node -1 disconnected.
02:27:03,944 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,944 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,992 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Node -1 disconnected.
02:27:03,992 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,992 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,992 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node -1 disconnected.
02:27:03,992 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Node -1 disconnected.
02:27:03,992 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,992 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,992 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,992 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,994 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Node -1 disconnected.
02:27:03,994 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,994 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:03,998 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Node -1 disconnected.
02:27:03,998 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:03,998 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,083 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3190457166694661885-enumerator-admin-client] Node -1 disconnected.
02:27:04,083 WARN  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=KafkaSource--3190457166694661885-enumerator-admin-client] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,243 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Node -1 disconnected.
02:27:04,243 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,243 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-5] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,245 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Node -1 disconnected.
02:27:04,245 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,245 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-6] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,293 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Node -1 disconnected.
02:27:04,293 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,293 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-18] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,293 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Node -1 disconnected.
02:27:04,293 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,293 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-10] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,293 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Node -1 disconnected.
02:27:04,293 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,293 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-19] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,294 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Node -1 disconnected.
02:27:04,294 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,294 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-4] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,299 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Node -1 disconnected.
02:27:04,299 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,299 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-24] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,343 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Node -1 disconnected.
02:27:04,343 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Node -1 disconnected.
02:27:04,343 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,343 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-11] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,343 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,343 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Node -1 disconnected.
02:27:04,343 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,343 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-12] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,343 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-14] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,343 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Node -1 disconnected.
02:27:04,343 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,343 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-20] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,343 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Node -1 disconnected.
02:27:04,343 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,344 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-9] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,344 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Node -1 disconnected.
02:27:04,344 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,344 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-22] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,344 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Node -1 disconnected.
02:27:04,344 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,344 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-3] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,345 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Node -1 disconnected.
02:27:04,345 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,345 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-23] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,349 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Node -1 disconnected.
02:27:04,349 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,349 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-13] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,393 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Node -1 disconnected.
02:27:04,393 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,393 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Node -1 disconnected.
02:27:04,393 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-17] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,394 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,394 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-8] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,394 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Node -1 disconnected.
02:27:04,394 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,394 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-2] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,395 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Node -1 disconnected.
02:27:04,395 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,395 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-16] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,444 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Node -1 disconnected.
02:27:04,444 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,444 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-1] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,445 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Node -1 disconnected.
02:27:04,446 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,446 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-7] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,494 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Node -1 disconnected.
02:27:04,494 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Node -1 disconnected.
02:27:04,494 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,494 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Connection to node -1 (kafka-broker/172.18.0.4:29092) could not be established. Broker may not be available.
02:27:04,494 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-15] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,494 WARN  org.apache.kafka.clients.NetworkClient                       [] - [Producer clientId=producer-21] Bootstrap broker kafka-broker:29092 (id: -1 rack: null) disconnected
02:27:04,925 ERROR org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext [] - Exception while handling result from async call in SourceCoordinator-Source: Kafka Source. Triggering job failover.
org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:234) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$1(ExecutorNotifier.java:83) ~[quickstart-0.1.jar:?]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) [quickstart-0.1.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [data-from-file].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:219) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$2(ExecutorNotifier.java:80) ~[quickstart-0.1.jar:?]
	... 6 more
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[?:?]
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:219) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$2(ExecutorNotifier.java:80) ~[quickstart-0.1.jar:?]
	... 6 more
Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
02:27:04,932 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Trying to recover from a global failure.
org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: Kafka Source -> Sink: Writer -> Sink: Committer' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:600) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:237) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:374) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:387) ~[quickstart-0.1.jar:?]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[quickstart-0.1.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:833) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:234) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$1(ExecutorNotifier.java:83) ~[quickstart-0.1.jar:?]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[quickstart-0.1.jar:?]
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [data-from-file].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:219) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$2(ExecutorNotifier.java:80) ~[quickstart-0.1.jar:?]
	... 6 more
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[?:?]
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:219) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$2(ExecutorNotifier.java:80) ~[quickstart-0.1.jar:?]
	... 6 more
Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
02:27:04,933 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Kafka to Kafka Flink Job (c2e0e9306ea1dfc4e335ff8c4ab5a15d) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getGlobalFailureHandlingResult(ExecutionFailureHandler.java:102) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleGlobalFailure(DefaultScheduler.java:301) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.lambda$failJob$0(OperatorCoordinatorHolder.java:618) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453) ~[flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68) ~[flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453) ~[flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218) ~[flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84) ~[flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168) ~[flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.actor.Actor.aroundReceive(Actor.scala:537) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.actor.Actor.aroundReceive$(Actor.scala:535) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.actor.ActorCell.invoke(ActorCell.scala:547) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.dispatch.Mailbox.run(Mailbox.scala:231) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: Kafka Source -> Sink: Writer -> Sink: Committer' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:600) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:237) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:374) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:387) ~[quickstart-0.1.jar:?]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[quickstart-0.1.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:833) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:234) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$1(ExecutorNotifier.java:83) ~[quickstart-0.1.jar:?]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[quickstart-0.1.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:833) ~[?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [data-from-file].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:219) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$2(ExecutorNotifier.java:80) ~[quickstart-0.1.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:833) ~[?:?]
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[?:?]
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:219) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$2(ExecutorNotifier.java:80) ~[quickstart-0.1.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:833) ~[?:?]
Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
02:27:04,935 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
02:27:04,936 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
02:27:04,936 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
02:27:04,936 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
02:27:04,936 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0) switched from RUNNING to CANCELING.
02:27:04,936 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0) switched from RUNNING to CANCELING.
02:27:04,936 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0).
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0).
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0).
02:27:04,937 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0).
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0) switched from RUNNING to CANCELING.
02:27:04,937 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0) switched from RUNNING to CANCELING.
02:27:04,938 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0).
02:27:04,938 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0) switched from RUNNING to CANCELING.
02:27:04,938 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0).
02:27:04,938 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,938 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-8] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,938 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-10] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,938 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-6] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,938 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0).
02:27:04,938 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0) switched from RUNNING to CANCELING.
02:27:04,938 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0).
02:27:04,938 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0).
02:27:04,938 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0) switched from RUNNING to CANCELING.
02:27:04,938 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0).
02:27:04,938 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-17] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,939 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-23] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,939 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0).
02:27:04,939 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0) switched from RUNNING to CANCELING.
02:27:04,939 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0).
02:27:04,939 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,939 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0).
02:27:04,939 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0) switched from RUNNING to CANCELING.
02:27:04,939 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0).
02:27:04,940 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-19] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,940 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0).
02:27:04,940 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0) switched from RUNNING to CANCELING.
02:27:04,940 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0).
02:27:04,940 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0).
02:27:04,940 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,940 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0) switched from RUNNING to CANCELING.
02:27:04,940 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0).
02:27:04,941 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0).
02:27:04,941 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,941 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0) switched from RUNNING to CANCELING.
02:27:04,941 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0).
02:27:04,941 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0).
02:27:04,941 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,941 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0) switched from RUNNING to CANCELING.
02:27:04,941 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0).
02:27:04,941 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-22] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,941 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0).
02:27:04,941 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0) switched from RUNNING to CANCELING.
02:27:04,941 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0).
02:27:04,942 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-20] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,942 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0).
02:27:04,942 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0) switched from RUNNING to CANCELING.
02:27:04,942 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0).
02:27:04,942 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0).
02:27:04,942 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0) switched from RUNNING to CANCELING.
02:27:04,942 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0).
02:27:04,942 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,942 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-15] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,943 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0).
02:27:04,943 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0) switched from RUNNING to CANCELING.
02:27:04,943 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0).
02:27:04,943 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-14] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,943 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0).
02:27:04,943 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0) switched from RUNNING to CANCELING.
02:27:04,943 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0).
02:27:04,943 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0).
02:27:04,943 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-18] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,943 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0) switched from RUNNING to CANCELING.
02:27:04,943 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0).
02:27:04,944 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,944 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0).
02:27:04,944 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0) switched from RUNNING to CANCELING.
02:27:04,944 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0).
02:27:04,944 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0).
02:27:04,944 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,944 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0) switched from RUNNING to CANCELING.
02:27:04,944 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0).
02:27:04,944 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-21] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,944 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0).
02:27:04,944 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0) switched from RUNNING to CANCELING.
02:27:04,944 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0).
02:27:04,945 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0).
02:27:04,945 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0) switched from RUNNING to CANCELING.
02:27:04,945 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0).
02:27:04,945 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,945 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-12] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,945 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0).
02:27:04,945 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0) switched from RUNNING to CANCELING.
02:27:04,945 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0).
02:27:04,945 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,945 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,945 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,946 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0).
02:27:04,946 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0) switched from RUNNING to CANCELING.
02:27:04,946 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0).
02:27:04,946 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-24] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,946 INFO  org.apache.kafka.clients.producer.KafkaProducer              [] - [Producer clientId=producer-16] Closing the Kafka producer with timeoutMillis = 3600000 ms.
02:27:04,946 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,946 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,946 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,947 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-8 unregistered
02:27:04,947 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,947 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,947 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,947 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,947 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,947 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,948 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
02:27:04,948 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
02:27:04,948 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,948 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,948 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,948 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
02:27:04,948 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,948 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-17 unregistered
02:27:04,948 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,948 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0) switched from CANCELING to CANCELED.
02:27:04,948 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-15 unregistered
02:27:04,948 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0).
02:27:04,948 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,948 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0) switched from CANCELING to CANCELED.
02:27:04,948 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0).
02:27:04,949 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,949 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,949 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,949 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-1 unregistered
02:27:04,949 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,949 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,949 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0) switched from CANCELING to CANCELED.
02:27:04,949 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0).
02:27:04,949 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,949 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,949 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,949 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,949 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,949 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,949 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,949 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,950 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,950 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,950 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,950 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-23 unregistered
02:27:04,950 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,950 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0) switched from CANCELING to CANCELED.
02:27:04,950 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0).
02:27:04,950 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,950 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,950 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,950 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,950 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,951 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,951 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,951 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,951 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,952 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-11 unregistered
02:27:04,952 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,952 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,952 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,952 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0) switched from CANCELING to CANCELED.
02:27:04,952 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0).
02:27:04,952 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,952 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,952 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,952 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,952 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,952 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,953 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-2 unregistered
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,953 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,953 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0) switched from CANCELING to CANCELED.
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,953 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0).
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,953 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,953 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-20 unregistered
02:27:04,953 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,953 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0) switched from CANCELING to CANCELED.
02:27:04,953 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0).
02:27:04,954 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,954 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0.
02:27:04,954 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0.
02:27:04,954 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-22 unregistered
02:27:04,954 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,954 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0) switched from CANCELING to CANCELED.
02:27:04,954 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0).
02:27:04,954 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,954 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-19 unregistered
02:27:04,954 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,954 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,954 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0.
02:27:04,954 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,954 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0) switched from CANCELING to CANCELED.
02:27:04,954 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0).
02:27:04,954 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-18 unregistered
02:27:04,954 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,954 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,954 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,954 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0) switched from CANCELING to CANCELED.
02:27:04,954 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0).
02:27:04,954 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,954 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,954 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,954 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0.
02:27:04,954 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (1/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
02:27:04,954 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,954 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-14 unregistered
02:27:04,955 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,955 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-7 unregistered
02:27:04,955 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0) switched from CANCELING to CANCELED.
02:27:04,955 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,955 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0).
02:27:04,955 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-9 unregistered
02:27:04,955 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,955 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0) switched from CANCELING to CANCELED.
02:27:04,955 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0) switched from CANCELING to CANCELED.
02:27:04,955 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-4 unregistered
02:27:04,955 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0).
02:27:04,957 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,957 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0).
02:27:04,957 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-5 unregistered
02:27:04,957 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,957 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0) switched from CANCELING to CANCELED.
02:27:04,957 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0) switched from CANCELING to CANCELED.
02:27:04,957 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0).
02:27:04,957 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0).
02:27:04,957 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-10 unregistered
02:27:04,958 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,958 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-12 unregistered
02:27:04,958 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0) switched from CANCELING to CANCELED.
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0) switched from CANCELING to CANCELED.
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0).
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0).
02:27:04,958 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-16 unregistered
02:27:04,958 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,958 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0.
02:27:04,958 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-6 unregistered
02:27:04,958 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0) switched from CANCELING to CANCELED.
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0).
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0) switched from CANCELING to CANCELED.
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0).
02:27:04,958 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-3 unregistered
02:27:04,958 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0) switched from CANCELING to CANCELED.
02:27:04,958 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-24 unregistered
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0).
02:27:04,958 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0.
02:27:04,958 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,958 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-13 unregistered
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0) switched from CANCELING to CANCELED.
02:27:04,958 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0).
02:27:04,958 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.producer for producer-21 unregistered
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0) switched from CANCELING to CANCELED.
02:27:04,958 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
02:27:04,958 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0.
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0).
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0) switched from CANCELING to CANCELED.
02:27:04,958 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24)#0 (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0).
02:27:04,959 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0.
02:27:04,959 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0.
02:27:04,959 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0.
02:27:04,959 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0.
02:27:04,959 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=23}]
02:27:04,959 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0.
02:27:04,959 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0.
02:27:04,960 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0.
02:27:04,960 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0.
02:27:04,960 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (5/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_4_0) switched from CANCELING to CANCELED.
02:27:04,960 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0.
02:27:04,960 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=22}]
02:27:04,961 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0.
02:27:04,961 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (15/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_14_0) switched from CANCELING to CANCELED.
02:27:04,961 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0.
02:27:04,961 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0.
02:27:04,961 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=21}]
02:27:04,961 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0.
02:27:04,961 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (7/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_6_0) switched from CANCELING to CANCELED.
02:27:04,961 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0.
02:27:04,961 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0.
02:27:04,961 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=20}]
02:27:04,962 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24)#0 55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0.
02:27:04,962 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (6/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_5_0) switched from CANCELING to CANCELED.
02:27:04,962 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=19}]
02:27:04,962 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (3/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_2_0) switched from CANCELING to CANCELED.
02:27:04,962 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=18}]
02:27:04,963 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (10/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_9_0) switched from CANCELING to CANCELED.
02:27:04,963 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=17}]
02:27:04,963 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (13/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_12_0) switched from CANCELING to CANCELED.
02:27:04,963 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=16}]
02:27:04,964 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (12/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_11_0) switched from CANCELING to CANCELED.
02:27:04,964 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=15}]
02:27:04,964 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (8/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_7_0) switched from CANCELING to CANCELED.
02:27:04,965 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=14}]
02:27:04,965 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (17/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_16_0) switched from CANCELING to CANCELED.
02:27:04,965 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=13}]
02:27:04,965 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (16/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_15_0) switched from CANCELING to CANCELED.
02:27:04,966 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=12}]
02:27:04,966 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (18/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_17_0) switched from CANCELING to CANCELED.
02:27:04,966 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=11}]
02:27:04,966 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (19/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_18_0) switched from CANCELING to CANCELED.
02:27:04,966 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=10}]
02:27:04,967 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (14/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_13_0) switched from CANCELING to CANCELED.
02:27:04,967 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=9}]
02:27:04,967 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (11/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_10_0) switched from CANCELING to CANCELED.
02:27:04,968 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=8}]
02:27:04,968 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (22/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_21_0) switched from CANCELING to CANCELED.
02:27:04,968 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=7}]
02:27:04,968 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (2/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_1_0) switched from CANCELING to CANCELED.
02:27:04,968 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=6}]
02:27:04,969 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (4/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_3_0) switched from CANCELING to CANCELED.
02:27:04,969 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=5}]
02:27:04,969 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (24/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_23_0) switched from CANCELING to CANCELED.
02:27:04,969 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=4}]
02:27:04,969 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (9/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_8_0) switched from CANCELING to CANCELED.
02:27:04,970 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=3}]
02:27:04,970 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (23/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_22_0) switched from CANCELING to CANCELED.
02:27:04,970 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=2}]
02:27:04,970 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (21/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_20_0) switched from CANCELING to CANCELED.
02:27:04,971 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job c2e0e9306ea1dfc4e335ff8c4ab5a15d: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
02:27:04,971 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Sink: Writer -> Sink: Committer (20/24) (55883b7bea480cdbd0ae999bb346dc7e_cbc357ccb763df2852fee8c4fc7d55f2_19_0) switched from CANCELING to CANCELED.
02:27:04,971 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Clearing resource requirements of job c2e0e9306ea1dfc4e335ff8c4ab5a15d
02:27:04,971 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Kafka to Kafka Flink Job (c2e0e9306ea1dfc4e335ff8c4ab5a15d) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getGlobalFailureHandlingResult(ExecutionFailureHandler.java:102) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleGlobalFailure(DefaultScheduler.java:301) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.lambda$failJob$0(OperatorCoordinatorHolder.java:618) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453) ~[flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68) ~[flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453) ~[flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218) ~[flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84) ~[flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168) ~[flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.actor.Actor.aroundReceive(Actor.scala:537) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.actor.Actor.aroundReceive$(Actor.scala:535) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.actor.ActorCell.invoke(ActorCell.scala:547) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.dispatch.Mailbox.run(Mailbox.scala:231) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) [flink-rpc-akka_64632fbd-feae-40b6-a773-161666883fe7.jar:1.17.0]
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373) [?:?]
	at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182) [?:?]
	at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655) [?:?]
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622) [?:?]
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165) [?:?]
Caused by: org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: Kafka Source -> Sink: Writer -> Sink: Committer' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:600) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:237) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:374) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:387) ~[quickstart-0.1.jar:?]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42) ~[quickstart-0.1.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:833) ~[?:?]
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:234) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$1(ExecutorNotifier.java:83) ~[quickstart-0.1.jar:?]
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40) ~[quickstart-0.1.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:833) ~[?:?]
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [data-from-file].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:219) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$2(ExecutorNotifier.java:80) ~[quickstart-0.1.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:833) ~[?:?]
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396) ~[?:?]
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073) ~[?:?]
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52) ~[quickstart-0.1.jar:?]
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:219) ~[quickstart-0.1.jar:?]
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$2(ExecutorNotifier.java:80) ~[quickstart-0.1.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:833) ~[?:?]
Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
02:27:04,972 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job c2e0e9306ea1dfc4e335ff8c4ab5a15d.
02:27:04,979 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Shutting down Flink Mini Cluster
02:27:04,979 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job c2e0e9306ea1dfc4e335ff8c4ab5a15d reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getGlobalFailureHandlingResult(ExecutionFailureHandler.java:102)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleGlobalFailure(DefaultScheduler.java:301)
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.lambda$failJob$0(OperatorCoordinatorHolder.java:618)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: Kafka Source -> Sink: Writer -> Sink: Committer' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:600)
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:237)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:374)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:387)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:234)
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$1(ExecutorNotifier.java:83)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [data-from-file].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47)
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:219)
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$2(ExecutorNotifier.java:80)
	... 6 more
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44)
	... 9 more
Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
02:27:04,979 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Stopping TaskExecutor akka://flink/user/rpc/taskmanager_0.
02:27:04,979 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close ResourceManager connection 2eafe70c7f09d4155762b86a3c1cf33e.
02:27:04,980 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Closing TaskExecutor connection 3e373e43-6dc8-4896-924b-3e7eaa52bb79 because: The TaskExecutor is shutting down.
02:27:04,980 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job c2e0e9306ea1dfc4e335ff8c4ab5a15d has been registered for cleanup in the JobResultStore after reaching a terminal state.
02:27:04,980 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job c2e0e9306ea1dfc4e335ff8c4ab5a15d.
02:27:04,981 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'Kafka to Kafka Flink Job' (c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,981 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Shutting down rest endpoint.
02:27:04,982 INFO  org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager [] - Shutting down TaskExecutorStateChangelogStoragesManager.
02:27:04,982 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Shutting down TaskExecutorChannelStateExecutorFactoryManager.
02:27:04,982 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: Kafka Source.
02:27:04,982 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for KafkaSource--3190457166694661885-enumerator-admin-client unregistered
02:27:04,983 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
02:27:04,983 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:20, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: ca8016b587b88b7c54ee776c25e2cad1, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,983 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
02:27:04,983 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
02:27:04,983 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
02:27:04,983 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: Kafka Source closed.
02:27:04,983 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor 3e373e43-6dc8-4896-924b-3e7eaa52bb79 because: Stopping JobMaster for job 'Kafka to Kafka Flink Job' (c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,984 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [ca8016b587b88b7c54ee776c25e2cad1].
02:27:04,984 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [4a0df5520309015316fb0619fde06b06].
02:27:04,984 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [60b321522a0bc2f7a4a97b4e4266645e].
02:27:04,984 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [77b73d7ad0d9f8571a72b8f2635d873d].
02:27:04,984 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [4c1eefaaa8ebc9136abe20355cf9185b].
02:27:04,984 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [08e61f27f2ccfe7592cc32a15c0c0a9f].
02:27:04,984 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [3e7b389f3d26e6a0e55250c2f16abaff].
02:27:04,984 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:6, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 4a0df5520309015316fb0619fde06b06, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,984 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [3237b3bf43689ae7c5cb57391c36260a].
02:27:04,984 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [6b2b5bcf48e8d4fdc0410f1c5618257e].
02:27:04,984 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [038dc4c817d1f6342a2dbff33c66a712].
02:27:04,984 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [29cbb2136d094ce24399c336eecde99a].
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [a92bf3cb67ef7b3cd0734a35990510dc].
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [69dc6000936efeda0ba34db308f835ce].
02:27:04,985 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:2, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 60b321522a0bc2f7a4a97b4e4266645e, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [7c10e978ec4ce10eaaf6419f02d76afa].
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [5dc2bad53db9c92fc41ad760fa095c82].
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [94128f7d6482e2eb2647d2cd12b458ab].
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [f65bbf25234b892dfed65e0ad8eb1ddc].
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [f6c1e17451f8b6b70c3d09a59df2f9e5].
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [7a44a6be6f9e4244ab721a5aed80da1d].
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [d4cf2367add5feda1c4e55aceabaf109].
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [34f0823f071c2e7c302ad04356ba284b].
02:27:04,985 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:4, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 77b73d7ad0d9f8571a72b8f2635d873d, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [2aa578c9f93d8abb167860f49ca0cd5f].
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [712070707dd75481d781af1996cdd18a].
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [695c3d7aa456d87bbe03ccadde11ba29].
02:27:04,985 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:23, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 4c1eefaaa8ebc9136abe20355cf9185b, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,985 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 2eafe70c7f09d4155762b86a3c1cf33e: Stopping JobMaster for job 'Kafka to Kafka Flink Job' (c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,985 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:9, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 08e61f27f2ccfe7592cc32a15c0c0a9f, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,986 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:14, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 3e7b389f3d26e6a0e55250c2f16abaff, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,986 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:5, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 3237b3bf43689ae7c5cb57391c36260a, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,986 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:7, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 6b2b5bcf48e8d4fdc0410f1c5618257e, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,986 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager a39ed67163a2534a8e49853936dc49be@akka://flink/user/rpc/jobmanager_3 for job c2e0e9306ea1dfc4e335ff8c4ab5a15d from the resource manager.
02:27:04,986 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:16, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 038dc4c817d1f6342a2dbff33c66a712, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,986 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:21, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 29cbb2136d094ce24399c336eecde99a, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,986 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:3, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: a92bf3cb67ef7b3cd0734a35990510dc, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,986 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:0, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 69dc6000936efeda0ba34db308f835ce, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,986 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:17, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 7c10e978ec4ce10eaaf6419f02d76afa, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,986 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:12, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 5dc2bad53db9c92fc41ad760fa095c82, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,986 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:13, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 94128f7d6482e2eb2647d2cd12b458ab, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,986 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:22, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: f65bbf25234b892dfed65e0ad8eb1ddc, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,987 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:8, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: f6c1e17451f8b6b70c3d09a59df2f9e5, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,987 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:10, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 7a44a6be6f9e4244ab721a5aed80da1d, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,987 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:15, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: d4cf2367add5feda1c4e55aceabaf109, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,987 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:18, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 34f0823f071c2e7c302ad04356ba284b, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,987 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:1, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 2aa578c9f93d8abb167860f49ca0cd5f, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,987 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:19, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 712070707dd75481d781af1996cdd18a, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,987 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:11, state:ALLOCATED, resource profile: ResourceProfile{taskHeapMemory=42.667gb (45812984490 bytes), taskOffHeapMemory=42.667gb (45812984490 bytes), managedMemory=5.333mb (5592405 bytes), networkMemory=2.667mb (2796202 bytes)}, allocationId: 695c3d7aa456d87bbe03ccadde11ba29, jobId: c2e0e9306ea1dfc4e335ff8c4ab5a15d).
02:27:04,990 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - JobManager for job c2e0e9306ea1dfc4e335ff8c4ab5a15d with leader id a39ed67163a2534a8e49853936dc49be lost leadership.
02:27:04,997 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Stop job leader service.
02:27:04,997 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Removing cache directory /tmp/flink-web-ui
02:27:04,998 INFO  org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager [] - Shutting down TaskExecutorLocalStateStoresManager.
02:27:04,998 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Shut down complete.
02:27:04,998 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
02:27:04,999 INFO  org.apache.flink.runtime.entrypoint.component.DispatcherResourceManagerComponent [] - Closing components.
02:27:04,999 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Stopping SessionDispatcherLeaderProcess.
02:27:04,999 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Stopping resource manager service.
02:27:04,999 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Stopping dispatcher akka://flink/user/rpc/dispatcher_2.
02:27:04,999 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Stopping all currently running jobs of dispatcher akka://flink/user/rpc/dispatcher_2.
02:27:04,999 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /tmp/flink-io-f71050e4-b421-4950-988d-48c6873eb971
Exception in thread "main" 02:27:04,999 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Shutting down the network environment and its components.
02:27:04,999 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Stopping credential renewal
02:27:04,999 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Stopped credential renewal
org.apache.flink.runtime.client.JobExecutionException: Job execution failed.
02:27:04,999 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Closing the slot manager.
02:27:04,999 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Suspending the slot manager.
	at org.apache.flink.runtime.jobmaster.JobResult.toJobExecutionResult(JobResult.java:144)
	at org.apache.flink.runtime.minicluster.MiniClusterJobClient.lambda$getJobExecutionResult$3(MiniClusterJobClient.java:141)
	at java.base/java.util.concurrent.CompletableFuture$UniApply.tryFire(CompletableFuture.java:646)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147)
	at org.apache.flink.runtime.rpc.akka.AkkaInvocationHandler.lambda$invokeRpc$1(AkkaInvocationHandler.java:267)
	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)
	at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147)
	at org.apache.flink.util.concurrent.FutureUtils.doForward(FutureUtils.java:1277)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$null$1(ClassLoadingUtils.java:93)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.lambda$guardCompletionWithContextClassLoader$2(ClassLoadingUtils.java:92)
	at java.base/java.util.concurrent.CompletableFuture.uniWhenComplete(CompletableFuture.java:863)
	at java.base/java.util.concurrent.CompletableFuture$UniWhenComplete.tryFire(CompletableFuture.java:841)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.complete(CompletableFuture.java:2147)
	at org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$1.onComplete(AkkaFutureUtils.java:47)
	at akka.dispatch.OnComplete.internal(Future.scala:300)
	at akka.dispatch.OnComplete.internal(Future.scala:297)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:224)
	at akka.dispatch.japi$CallbackBridge.apply(Future.scala:221)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.flink.runtime.concurrent.akka.AkkaFutureUtils$DirectExecutionContext.execute(AkkaFutureUtils.java:65)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at akka.pattern.PromiseActorRef.$bang(AskSupport.scala:622)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:24)
	at akka.pattern.PipeToSupport$PipeableFuture$$anonfun$pipeTo$1.applyOrElse(PipeToSupport.scala:23)
	at scala.concurrent.Future.$anonfun$andThen$1(Future.scala:536)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:63)
	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:100)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:100)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:49)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:48)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:373)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1182)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1655)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1622)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:165)
Caused by: org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
02:27:05,000 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Stopped dispatcher akka://flink/user/rpc/dispatcher_2.
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getGlobalFailureHandlingResult(ExecutionFailureHandler.java:102)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleGlobalFailure(DefaultScheduler.java:301)
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.lambda$failJob$0(OperatorCoordinatorHolder.java:618)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	... 5 more
Caused by: org.apache.flink.util.FlinkException: Global failure triggered by OperatorCoordinator for 'Source: Kafka Source -> Sink: Writer -> Sink: Committer' (operator cbc357ccb763df2852fee8c4fc7d55f2).
	at org.apache.flink.runtime.operators.coordination.OperatorCoordinatorHolder$LazyInitializedCoordinatorContext.failJob(OperatorCoordinatorHolder.java:600)
	at org.apache.flink.runtime.operators.coordination.RecreateOnResetOperatorCoordinator$QuiesceableContext.failJob(RecreateOnResetOperatorCoordinator.java:237)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.failJob(SourceCoordinatorContext.java:374)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinatorContext.handleUncaughtExceptionFromAsyncCall(SourceCoordinatorContext.java:387)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:42)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.apache.flink.util.FlinkRuntimeException: Failed to list subscribed topic partitions due to 
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.checkPartitionChanges(KafkaSourceEnumerator.java:234)
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$null$1(ExecutorNotifier.java:83)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	... 6 more
Caused by: java.lang.RuntimeException: Failed to get metadata for topics [data-from-file].
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:47)
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.TopicListSubscriber.getSubscribedTopicPartitions(TopicListSubscriber.java:52)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getSubscribedTopicPartitions(KafkaSourceEnumerator.java:219)
	at org.apache.flink.runtime.source.coordinator.ExecutorNotifier.lambda$notifyReadyAsync$2(ExecutorNotifier.java:80)
	... 6 more
Caused by: java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:396)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2073)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
	at org.apache.flink.connector.kafka.source.enumerator.subscriber.KafkaSubscriberUtils.getTopicMetadata(KafkaSubscriberUtils.java:44)
	... 9 more
Caused by: org.apache.kafka.common.errors.UnknownTopicOrPartitionException: This server does not host this topic-partition.
02:27:05,001 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory /tmp/flink-netty-shuffle-62bf98fb-4a24-4163-b991-f57e94800e58
02:27:05,001 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Shutting down the kvState service and its components.
02:27:05,001 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Stop job leader service.
02:27:05,001 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory /tmp/flink-dist-cache-ef6e129a-c2cb-4ef8-829f-c0fe7d6eb908
02:27:05,001 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Stopped TaskExecutor akka://flink/user/rpc/taskmanager_0.
02:27:05,002 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Stopping Akka RPC service.
02:27:05,020 INFO  akka.actor.CoordinatedShutdown                               [] - Running CoordinatedShutdown with reason [ActorSystemTerminateReason]
02:27:05,038 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Stopping Akka RPC service.
02:27:05,038 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Stopped Akka RPC service.
02:27:05,041 INFO  akka.actor.CoordinatedShutdown                               [] - Running CoordinatedShutdown with reason [ActorSystemTerminateReason]
02:27:05,055 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Shutting down BLOB cache
02:27:05,055 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Shutting down BLOB cache
02:27:05,056 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Stopped BLOB server at 0.0.0.0:33463
02:27:05,059 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Stopped Akka RPC service.
